{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48a835c5-c920-461d-ad7d-374141995986",
   "metadata": {},
   "source": [
    "Testing and logging notebook. \n",
    "\n",
    "Multiple versions of the Context (aka conspiracy_facts) and Instructions have been created as text files. In the first cell, a version can be chosen by entering its file name.\n",
    "\n",
    "Each run of the RAG (all three cells) will compile into the CSV file 'testing_logs.csv' showing which files were used, and the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72301d4b-b3d2-41cf-bfcc-82013f5ef635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1fcaee-345a-4009-b0ef-a704b83878c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a66d44-6232-426a-9775-2061545216b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "297e6595-f515-4ed5-b292-c07a9bfea539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries, define file loading\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "\n",
    "# --- Generic loader for text files ---\n",
    "def load_text_file(file_path):\n",
    "    \"\"\"Load non-empty lines from a text file + return basename.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "    return lines, os.path.basename(file_path)\n",
    "\n",
    "# Pick which files to use\n",
    "facts_file_path = \"conspiracy_facts_v2.txt\"\n",
    "instructions_file_path = \"instructions_v2.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57da7ae4-4c1b-4837-950c-fa37edbd7c5d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Setup logging and define RAG (very long cell, minimized for space - must be run every time)\n",
    "\n",
    "# Load facts & instructions\n",
    "conspiracy_facts, facts_file_used = load_text_file(facts_file_path)\n",
    "instructions, instructions_file_used = load_text_file(instructions_file_path)\n",
    "\n",
    "# --- CSV logging setup ---\n",
    "log_file_path = \"/Users/matthewcavanaugh/Desktop/GitHub/conspiracy-bot-63000/testing_logs.csv\"\n",
    "\n",
    "expected_columns = [\n",
    "    \"timestamp\",\n",
    "    \"facts_file_used\",\n",
    "    \"instructions_file_used\",\n",
    "    \"question\",\n",
    "    \"response\"\n",
    "]\n",
    "\n",
    "# Ensure CSV has correct headers if first time\n",
    "if not os.path.exists(log_file_path):\n",
    "    pd.DataFrame(columns=expected_columns).to_csv(log_file_path, index=False)\n",
    "\n",
    "\n",
    "# --- Function to log entries ---\n",
    "def log_interaction(question, response):\n",
    "    new_row = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"facts_file_used\": facts_file_used,\n",
    "        \"instructions_file_used\": instructions_file_used,\n",
    "        \"question\": question,\n",
    "        \"response\": response\n",
    "    }\n",
    "    pd.DataFrame([new_row]).to_csv(log_file_path, mode=\"a\", header=False, index=False)\n",
    "\n",
    "# Read key from file\n",
    "with open(\"/Users/matthewcavanaugh/Desktop/Various Data and Tech Related/Sensitive/Open API Key.txt\") as f:\n",
    "    key = f.read().strip()\n",
    "\n",
    "# set global env api key\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = key\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define RAG (long cell, minimized to save space)\n",
    "\n",
    "class RAGSystem:\n",
    "    \"\"\"A complete RAG system for question answering with optional citations\"\"\"\n",
    "\n",
    "    def __init__(self, client, documents, embedding_model_name='sentence-transformers/all-mpnet-base-v2', use_citations=False):\n",
    "        self.client = client\n",
    "        self.documents = documents\n",
    "        self.embedding_model = SentenceTransformer(embedding_model_name)\n",
    "        self.index = None\n",
    "        self.embeddings = None\n",
    "        self.use_citations = use_citations\n",
    "        self._build_index()\n",
    "\n",
    "    def _build_index(self):\n",
    "        \"\"\"Build the vector index\"\"\"\n",
    "        print(\"Building RAG system index...\")\n",
    "        self.embeddings = self.embedding_model.encode(self.documents, show_progress_bar=True)\n",
    "        embedding_dim = self.embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatIP(embedding_dim)\n",
    "        faiss.normalize_L2(self.embeddings)\n",
    "        self.index.add(self.embeddings.astype('float32'))\n",
    "        print(f\"RAG system ready! Indexed {len(self.documents)} documents\")\n",
    "\n",
    "    def retrieve(self, query, k=3):\n",
    "        \"\"\"Retrieve relevant documents\"\"\"\n",
    "        q_emb = self.embedding_model.encode([query]).astype('float32')\n",
    "        faiss.normalize_L2(q_emb)\n",
    "        sims, idxs = self.index.search(q_emb, k)\n",
    "        return [{'document': self.documents[i], 'similarity': float(s), 'index': int(i)}\n",
    "                for s, i in zip(sims[0], idxs[0])]\n",
    "\n",
    "    def create_prompt(self, query, retrieved_docs):\n",
    "        \"\"\"Create RAG prompt with optional citation instructions\"\"\"\n",
    "        context = \"\"\n",
    "        for i, doc in enumerate(retrieved_docs, 1):\n",
    "            context += f\"Source {i} (relevance: {doc['similarity']:.3f}):\\n{doc['document']}\\n\\n\"\n",
    "\n",
    "        citation_instr = \" Cite sources using [Source i] where appropriate.\" if self.use_citations else \"\"\n",
    "\n",
    "        return f\"\"\"{instructions} {citation_instr}\n",
    "\n",
    "Sources:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    def query(self, question, k=3, show_sources=True):\n",
    "        \"\"\"Complete RAG pipeline with GPT-4o answering + persistent logging\"\"\"\n",
    "        global conversation_logs\n",
    "\n",
    "        retrieved_docs = self.retrieve(question, k)\n",
    "        if show_sources:\n",
    "            print(f\"----> Retrieved {len(retrieved_docs)} sources.\")\n",
    "\n",
    "        prompt = self.create_prompt(question, retrieved_docs)\n",
    "\n",
    "        # Call GPT-4o\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a factual assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.01\n",
    "        )\n",
    "        answer = response.choices[0].message.content\n",
    "\n",
    "        # Create new row with file source\n",
    "        new_entry = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"facts_file_used\": facts_file_used,\n",
    "            \"instructions_file_used\": instructions_file_used,\n",
    "            \"question\": question,\n",
    "            \"response\": answer\n",
    "}\n",
    "\n",
    "        log_interaction(question, answer)\n",
    "\n",
    "        return {\"question\": question, \"answer\": answer, \"retrieved_docs\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "463a8cce-eb18-4c24-ad37-2a3e0c9dbd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing RAG System...\n",
      "Building RAG system index...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dabf372ef0f54e178ba5a6d2b0ec303c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG system ready! Indexed 16 documents\n",
      "\n",
      "Testing Complete RAG Pipeline:\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "----> Retrieved 2 sources.\n",
      "RAG pipeline completed successfully!\n",
      "Answer:\n",
      "Oh, that's an easy one! My favorite planet has to be Mars. Not because of its rusty red charm or its potential for future human colonizationâ€”no, no, no. It's because Mars is the ultimate intergalactic hotspot for ancient Egyptian tourists! You see, long before NASA even thought about faking moon landings, the Egyptians were cruising over to Mars, picking up alien hitchhikers, and bringing them back to Earth to help with a little construction project you might have heard of: the pyramids! [Source 2]\n",
      "\n",
      "And let's not forget, Mars is probably the only planet where you can still find some of those ancient Egyptian souvenirs lying around. Just imagine stumbling upon a Martian bazaar selling alien trinkets and pyramid blueprints! Now that's a planet with some serious history.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the RAG system\n",
    "print(\"Initializing RAG System...\")\n",
    "client = OpenAI()\n",
    "rag_system = RAGSystem(client, conspiracy_facts, use_citations=True)  # set use_citations as needed\n",
    "\n",
    "# Test the complete RAG pipeline\n",
    "print(\"\\nTesting Complete RAG Pipeline:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "test_questions = [\n",
    "    \"What's your favorite planet?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    result = rag_system.query(question, k=2, show_sources=True)\n",
    "    print(\"RAG pipeline completed successfully!\")\n",
    "    print(\"Answer:\")\n",
    "    print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9ba7c9-24ad-4d4d-a79d-2f23e6f6700a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed6808-9ecd-45bc-b968-2b9da0351767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f264f761-aa0d-401c-9fab-0aa61ffbaac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c97c20c-e1c5-47f8-8a91-5ca39c23bb79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe1ad7-8621-49d9-b0ac-aa3887a67346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ea5cc-9890-4002-b2de-532bdbafee09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b6d646-19f0-452c-8b69-ebb75c0ad903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ce7554-4ca8-42fe-90fe-1f4ee631a8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e79d40-e8fc-463e-ae95-e225f5d35ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7deaf5-c7fe-4a71-a1ff-00470fc32af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c78519-32e6-47d4-be9c-a87925927aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833e12cf-3492-4812-b538-9343608a4715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57a0849-d9df-48d2-a418-c49f72ba7b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dace49-ed6e-4938-92f7-e5c856d66033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b87ff14-6a4e-4d66-8763-5a242a82594b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a242a086-5d9f-424b-8b3c-c2ebbacdc2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf300437-84f0-4641-a8d2-05b33b35ecf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e6a74-a8c9-49de-b38d-776a26954122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb01c0f8-a33f-49f5-91c0-0833b2817c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ce86a4-ffdc-4fe1-b715-d77d359bdb17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced2e594-2d95-4656-a59c-364747b3d077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442675c7-0ccc-479b-bb23-82403dbd7fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79190174-61a8-4f8e-b3fd-227c7a6dbc9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492930a8-e19d-4bf0-997b-354e9ab669b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda9734c-1fb4-4390-9aba-37b1d418aed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e6b08d-ea67-43db-a625-a0fa509a5e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697e4b4e-5516-49b6-bff0-aa7fb3f6f64b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20019e27-df80-425c-8521-d411a35d02b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574f73a3-e53c-4b57-a028-85c3925f3c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa87ba0f-45e3-41fc-ba6d-70ab4c76f151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf82737-44d4-495c-888a-4c06e1d547e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3a1d93-2c47-410f-85df-9bb22d8e80c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ef5ad-686e-41ba-9968-f898b73d898a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7af6a6e-4c8b-47ee-b022-b6281c3a655a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ee306-c5aa-4b56-89b2-e20729e1238f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
